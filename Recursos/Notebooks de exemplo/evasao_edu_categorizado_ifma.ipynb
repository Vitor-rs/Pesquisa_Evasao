{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitorGit93/Pesquisa_Evasao/blob/main/Recursos/Notebooks%20de%20exemplo/evasao_edu_categorizado_ifma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "EoDrvVIqq8rH"
      },
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "#plt.style.use('ggplot')\n",
        "#ggplot is R based visualisation package that provides better graphics with higher level of abstraction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb40452ad5ae975fd33307735fd47c33f1aca999",
        "id": "IMHMWRzvq8rI"
      },
      "cell_type": "markdown",
      "source": [
        "## Basic Data Science and ML Pipeline"
      ]
    },
    {
      "metadata": {
        "_uuid": "478f0929dd095b53a8e89dcddf7f503dd11203ab",
        "id": "gabRTEVoq8rJ"
      },
      "cell_type": "markdown",
      "source": [
        "## OSEMN Pipeline\n",
        "* O - Obtendo nossos dados\n",
        "* S - limpeza de nossos dados\n",
        "* E - Explorar / visualizar nossos dados nos permitirá encontrar padrões e tendências\n",
        "* M - Modelar nossos dados nos dará nosso poder preditivo como assistente\n",
        "* N - Interpretando nossos dados\n",
        "\n",
        "\n",
        "For reference : https://www.linkedin.com/pulse/life-data-science-osemn-randy-lao/?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_post_details%3BmDlg5VsdSBCLBps2R0vRZA%3D%3D"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3977359aa7f65cc9d96fdf0ede4e99116fb314c6",
        "id": "YYqEDufdq8rJ"
      },
      "cell_type": "code",
      "source": [
        "#Carregando nosso dataset\n",
        "#evasao_data = pd.read_csv('../input/baseeducategorizacaosocial2klimredux/BaseEduCatRedux_Limit.csv')\n",
        "evasao_data = pd.read_csv('../input/base-edu-cat-social-1-para-1b/BaseEduCat1p1.csv')\n",
        "\n",
        "#Mostrando as 5 primeiras linhas de nosso dataset\n",
        "evasao_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e19cd0e1959c38d52ed8c437b42f3ccd61e92fb4",
        "id": "4fsq5sztq8rK"
      },
      "cell_type": "markdown",
      "source": [
        "## Análise exploratória de dados\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "650e7357fe6d26e6a557cc3088d9b1147b6093ea",
        "id": "MoSdngqPq8rK"
      },
      "cell_type": "code",
      "source": [
        "## mostra informações como tipo de dados, colunas, valores null encontrados, memoria usada etc\n",
        "## function reference : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\n",
        "evasao_data.info(verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4be617d9cdcb165ef3286163a22003877732ad0b",
        "id": "e0VVyOJAq8rL"
      },
      "cell_type": "markdown",
      "source": [
        "* **DataFrame.describe()** gera estatísticas descritivas que resumem a tendência central, dispersão e forma da distribuição de um conjunto de dados, excluindo os valores de NaN. Este método nos diz muitas coisas sobre um conjunto de dados. Uma coisa importante é que o método describe() lida apenas com valores numéricos. Não funciona com nenhum valor categórico. Portanto, se houver algum valor categórico em uma coluna, o método describe() o ignorará e exibirá um resumo para as outras colunas, a menos que o parâmetro include = \"all\" seja passado..\n",
        "\n",
        "Vamos entender as estatísticas que são geradas pelo método describe() :\n",
        "* count nos diz o numero de linhas não vazias.\n",
        "* mean indica o valor médio.\n",
        "* std indica o valor do desvio padrão.\n",
        "* min indica o valor minimo.\n",
        "* 25%, 50%, and 75% indicam percentuais de cada recurso. util para identificar valores extremos.\n",
        "* max indica o valor máximo."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZGb15dM7q8rM"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0682a8c7acbdb75ad600df7b7cd732f4d5b0a17f",
        "id": "KWqIYasiq8rM"
      },
      "cell_type": "code",
      "source": [
        "## estatísticas básicas detalhadas sobre o dado (observe que apenas colunas numéricas seriam exibidas aqui, a menos que o parâmetro include=\"all\")\n",
        "## for reference: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe\n",
        "evasao_data.describe()\n",
        "\n",
        "## Veja também :\n",
        "## para retornar colunas de um tipo específico: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de488e0ee803ee6d4084c92df3f548eb6a051d43",
        "id": "2fM9TEbPq8rM"
      },
      "cell_type": "code",
      "source": [
        "evasao_data.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1143fa069d6ff7b0c4decda62fa167a7a01b86a1",
        "id": "OlvP7kGcq8rN"
      },
      "cell_type": "markdown",
      "source": [
        "### Questão Importante\n",
        "\n",
        "#### O valor mínimo das colunas listadas abaixo pode ser zero (0)?\n",
        "\n",
        "Nessas colunas, um valor zero não faz sentido e, portanto, indica o valor ausente.\n",
        "\n",
        "As colunas ou variáveis a seguir possuem um valor zero inválido:\n",
        "\n",
        "1. ira_novo\n",
        "2. renda_per_capita\n",
        "\n",
        "'ira_novo','renda_per_capita'\n",
        "\n",
        "2. periodo_atual\n",
        "3. ocorrencias\n",
        "4. qtd_filhos\n",
        "5. possui_necessidade_especial\n",
        "6. ficou_tempo_sem_estudar\n",
        "\n",
        "8. possui_conhecimento_idiomas\n",
        "9. possui_conhecimento_informatica\n",
        "\n",
        "\n",
        "\n",
        "'ira','periodo_atual','ocorrencias','qtd_filhos','possui_necessidade_especial','ficou_tempo_sem_estudar','renda_per_capita','possui_conhecimento_idiomas','possui_conhecimento_informatica'\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "a5c66431403ac1246f52e4256b09b660fc273c25",
        "id": "WXzjBUFBq8rN"
      },
      "cell_type": "markdown",
      "source": [
        "#### Assim, é melhor substituir zeros por nan, pois depois disso contá-los seria mais fácil e os zeros precisariam ser substituídos por valores adequados\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "506fa58605d641694883cad75bb3683dafdb0356",
        "id": "xet2h6cbq8rO"
      },
      "cell_type": "code",
      "source": [
        "evasao_data_copy = evasao_data.copy(deep = True)\n",
        "##diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
        "evasao_data_copy[['ira_novo','renda_per_capita']] = evasao_data_copy[['ira_novo','renda_per_capita']].replace(0,np.NaN)\n",
        "\n",
        "## showing the count of Nans\n",
        "print(evasao_data_copy.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20bf4545b4d80cd00061d08d3cc2206d0b80f376",
        "id": "nejoLdGyq8rP"
      },
      "cell_type": "code",
      "source": [
        "#### Para preencher esses valores Nan, a distribuição de dados precisa ser entendida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dQ5xEswfq8rP"
      },
      "cell_type": "code",
      "source": [
        "evasao_data_copy.head()\n",
        "evasao_data_copy.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5ef22db6afea0d63189599fb4abbb2b3f53ccb5",
        "id": "tRRj_XiWq8rP"
      },
      "cell_type": "code",
      "source": [
        "p = evasao_data.hist(figsize = (20,20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "337635cc5b94f7bf6b1a95f5d4043e67604c2c8a",
        "id": "jWJU95t_q8rQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Com o objetivo de imputar valores de nan para as colunas de acordo com sua distribuição\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0568a737f6529e711d3e1ffa5493f0fa749efff3",
        "id": "1_YBbL3Pq8rQ"
      },
      "cell_type": "code",
      "source": [
        "## diabetes_data_copy['BMI'].fillna(diabetes_data_copy['BMI'].median(), inplace = True)\n",
        "\n",
        "evasao_data_copy['ira_novo'].fillna(evasao_data_copy['ira_novo'].median(), inplace = True)\n",
        "evasao_data_copy['renda_per_capita'].fillna(evasao_data_copy['renda_per_capita'].median(), inplace = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1bf99a7a106d92072207b4a5071098ac32c03902",
        "id": "ezZ7hB_Iq8rQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotando após renover Nan"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b54f61be1a5b6fc75a90bfdcdfdb1df18a38594",
        "id": "F54ZtMpjq8rQ"
      },
      "cell_type": "code",
      "source": [
        "p = evasao_data_copy.hist(figsize = (20,20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc09dd32d8cf836fd9afbb8f4d83d47260b89e91",
        "id": "2vJvuV9Bq8rR"
      },
      "cell_type": "markdown",
      "source": [
        "## Skewness (Assimetria)\n",
        "\n",
        "A ***left-skewed distribution*** has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That’s because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n",
        "\n",
        "A ***right-skewed distribution*** has a long right tail. Right-skewed distributions are also called positive-skew distributions. That’s because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n",
        "\n",
        "\n",
        "![](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2014/02/pearson-mode-skewness.jpg)\n",
        "\n",
        "\n",
        "#### to learn more about skewness\n",
        "https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/skewed-distribution/"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8322614f5de4888d713c0468a43ae2a3eb1b8862",
        "id": "nSfXo29eq8rR"
      },
      "cell_type": "code",
      "source": [
        "## observing the shape of the data\n",
        "evasao_data_copy.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c69e3cf2bce422520047daa7b02b688e42c197e4",
        "id": "sfOTaUg5q8rR"
      },
      "cell_type": "code",
      "source": [
        "## data type analysis\n",
        "#plt.figure(figsize=(5,5))\n",
        "#sns.set(font_scale=2)\n",
        "sns.countplot(y=evasao_data.dtypes ,data=evasao_data)\n",
        "plt.xlabel(\"contagem de cada tipo\")\n",
        "plt.ylabel(\"tipos de dados\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d5a4e88b691d25e8c661e3e292f5d81d33c576e",
        "id": "z92Hw2M9q8rS"
      },
      "cell_type": "code",
      "source": [
        "## null count analysis\n",
        "import missingno as msno\n",
        "p=msno.bar(evasao_data_copy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "009e21b28bb9fcb64bd0b841d0aa09597b9bbea8",
        "id": "-o7OcptVq8rS"
      },
      "cell_type": "code",
      "source": [
        "## checando o balanceamento dos dados para plotar a contagem de resultados por seus valores\n",
        "color_wheel = {1: \"#0392cf\",\n",
        "               2: \"#7bc043\"}\n",
        "colors = evasao_data_copy[\"Outcome\"].map(lambda x: color_wheel.get(x + 1))\n",
        "print(evasao_data_copy.Outcome.value_counts())\n",
        "p=evasao_data_copy.Outcome.value_counts().plot(kind=\"bar\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48fd3f1b1b8c38b94d06fb4a4daf4afd592beb15",
        "id": "ubRIXKB5q8rS"
      },
      "cell_type": "markdown",
      "source": [
        "#### O gráfico acima mostra que os dados são direcionados para pontos de dados com valor de resultado igual a 0, onde isso significa que não ocorreu evasão."
      ]
    },
    {
      "metadata": {
        "_uuid": "87dc25ce0f9036237af2b8fb8560d7ba575df22c",
        "id": "n3TNdOwaq8rS"
      },
      "cell_type": "markdown",
      "source": [
        "#### Scatter matrix of uncleaned data\n",
        "Matriz de dispersão de dados não limpos"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f100c23bcf63fa58180813ff594dfff591bb20ed",
        "id": "fQ1fXxMYq8rT"
      },
      "cell_type": "code",
      "source": [
        "from pandas.tools.plotting import scatter_matrix\n",
        "p=scatter_matrix(evasao_data,figsize=(25, 25))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2503e0f31903aa2a3522f8c9e0771ea9aff7217",
        "id": "ynqAQ1Ggq8rT"
      },
      "cell_type": "markdown",
      "source": [
        "###### The pairs plot builds on two basic figures, the histogram and the scatter plot. The histogram on the diagonal allows us to see the distribution of a single variable while the scatter plots on the upper and lower triangles show the relationship (or lack thereof) between two variables.\n",
        "O gráfico de pares baseia-se em duas figuras básicas, o histograma e o gráfico de dispersão. O histograma na diagonal nos permite ver a distribuição de uma única variável, enquanto os gráficos de dispersão nos triângulos superior e inferior mostram a relação (ou a falta dela) entre duas variáveis.\n",
        "\n",
        "For Reference: https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166"
      ]
    },
    {
      "metadata": {
        "_uuid": "47a5993e4001d4ffc0ddf2dd59740045048ba738",
        "id": "wwfxTYgrq8rT"
      },
      "cell_type": "markdown",
      "source": [
        "#### Pair plot for clean data\n",
        "Gráfico de par para dados limpos"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3adefc9ab47271b11f13687a245df6ced9f1b312",
        "id": "WT5cuyCQq8rU"
      },
      "cell_type": "code",
      "source": [
        "p=sns.pairplot(evasao_data_copy, hue = 'Outcome')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "108b278e68021929a5c8cd186afc4848f1767986",
        "id": "t9irtGoOq8rU"
      },
      "cell_type": "markdown",
      "source": [
        "***Pearson's Correlation Coefficient***: helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.\n",
        "\n",
        "A heat map is a two-dimensional representation of information with the help of colors. Heat maps can help the user visualize simple or complex information.\n",
        "\n",
        "Coeficiente de correlação de Pearson: ajuda a descobrir a relação entre duas quantidades. Ele fornece a medida da força da associação entre duas variáveis. O valor do coeficiente de correlação de Pearson pode estar entre -1 e +1.\n",
        "* 1 significa que eles são altamente correlacionados e\n",
        "* 0 significa que não há correlação.\n",
        "\n",
        "Um mapa de calor é uma representação bidimensional da informação com a ajuda de cores. Os mapas de calor podem ajudar o usuário a visualizar informações simples ou complexas."
      ]
    },
    {
      "metadata": {
        "_uuid": "9dbea8e64dd833ce466c5d0585f4d8ad5bbfe8ff",
        "id": "QURf0nj_q8rU"
      },
      "cell_type": "markdown",
      "source": [
        "#### Mapa de calor para dados impuros"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2971ad528058ac82e54eec7b42b814644cef4195",
        "id": "E2EOQBdfq8rV"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\n",
        "p=sns.heatmap(evasao_data.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a97ddd37b576e90c5cc192bd8ab46a4d44c960af",
        "id": "qqSINv_2q8rV"
      },
      "cell_type": "markdown",
      "source": [
        "#### Mapa de calor para dados limpos"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b000ace1a6558c57c0b485c66a5bdb84063174b",
        "id": "PYaIj1l8q8rV"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\n",
        "p=sns.heatmap(evasao_data_copy.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5e5142438fcc7973b722337deb24ba2061e14316",
        "id": "nRLD8K8xq8rV"
      },
      "cell_type": "markdown",
      "source": [
        "## Scaling the data\n",
        "data Z is rescaled such that μ = 0 and 𝛔 = 1, and is done through this formula:\n",
        "![](https://cdn-images-1.medium.com/max/800/0*PXGPVYIxyI_IEHP7.)\n",
        "\n",
        "\n",
        "#### to learn more about scaling techniques\n",
        "https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc\n",
        "https://machinelearningmastery.com/rescaling-data-for-machine-learning-in-python-with-scikit-learn/"
      ]
    },
    {
      "metadata": {
        "_uuid": "2cf6c9ff22d3a7af35e399406e7565055ca6af36",
        "trusted": true,
        "id": "uZQA59goq8rb"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "##X =  pd.DataFrame(sc_X.fit_transform(evasao_data_copy.drop([\"Outcome\"],axis = 1),),\n",
        "##        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
        "##       'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
        "##        columns=['ira_novo', 'ativo', 'curso_campus_id', 'turno_id', 'situacao_id',\n",
        "##                 'periodo_atual', 'periodo_letivo', 'ano_letivo_id', 'ocorrencias',\n",
        "##                 'raca_id', 'estado_civil_id', 'qtd_filhos', 'pai_nivel_escolaridade_id',\n",
        "##                 'mae_nivel_escolaridade_id', 'possui_necessidade_especial',\n",
        "##                 'ficou_tempo_sem_estudar', 'qtd_pessoas_domicilio_antes_ifma',\n",
        "##                 'tipo_moradia_id', 'renda_per_capita', 'tipo_imovel_residencial_id',\n",
        "##                 'tipo_area_residencial_id', 'possui_conhecimento_idiomas', 'possui_conhecimento_informatica'])\n",
        "\n",
        "\n",
        "X =  pd.DataFrame(sc_X.fit_transform(evasao_data_copy.drop([\"Outcome\"],axis = 1),),\n",
        "        columns=['ira_novo', 'ativo', 'curso_campus_id', 'turno_id', 'situacao_id',\n",
        "                 'periodo_atual', 'periodo_letivo', 'ano_letivo_id', 'ocorrencias',\n",
        "                 'raca_id', 'estado_civil_id', 'qtd_filhos', 'pai_nivel_escolaridade_id',\n",
        "                 'mae_nivel_escolaridade_id', 'possui_necessidade_especial',\n",
        "                 'ficou_tempo_sem_estudar', 'qtd_pessoas_domicilio_antes_ifma',\n",
        "                 'tipo_moradia_id', 'renda_per_capita', 'tipo_imovel_residencial_id',\n",
        "                 'tipo_area_residencial_id', 'possui_conhecimento_idiomas',\n",
        "                 'possui_conhecimento_informatica'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e10c79fe13861fb0fbe714c977f93bb8ed90a5fd",
        "id": "4cwjK-7jq8rb"
      },
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d9bd9ecd9612fb32f0629a8a3c0a85a14b034cf",
        "id": "vYMRtjCUq8rc"
      },
      "cell_type": "code",
      "source": [
        "#X = diabetes_data.drop(\"Outcome\",axis = 1)\n",
        "y = evasao_data_copy.Outcome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f87d51b88980792d54d8f3ba60c2c7b91d03cad3",
        "id": "_kcE3YVfq8rc"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Train Split and Cross Validation methods\n",
        "\n",
        "\n",
        "\n",
        "***Train Test Split*** : To have unknown datapoints to test the data rather than testing with the same points with which the model was trained. This helps capture the model performance much better.\n",
        "\n",
        "***Train Test Split*** : Ter pontos de dados desconhecidos para testar os dados em vez de testar com os mesmos pontos com os quais o modelo foi treinado. Isso ajuda a capturar o desempenho do modelo muito melhor\n",
        "\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*-8_kogvwmL1H6ooN1A1tsQ.png)\n",
        "\n",
        "***Cross Validation***: When model is split into training and testing it can be possible that specific type of data point may go entirely into either training or testing portion. This would lead the model to perform poorly. Hence over-fitting and underfitting problems can be well avoided with cross validation techniques.\n",
        "\n",
        "***Validação Cruzada***: Quando o modelo é dividido em treinamento e teste, pode ser possível que um tipo específico de ponto de dados entre inteiramente na parte de treinamento ou teste. Isso levaria o modelo a ter um desempenho ruim. Portanto, problemas de ajuste excessivo e insuficiente podem ser bem evitados com técnicas de validação cruzada\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/1*4G__SV580CxFj78o9yUXuQ.png)\n",
        "\n",
        "\n",
        "***About Stratify*** : Stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify.\n",
        "***About Stratify*** : O parâmetro Stratify faz uma divisão para que a proporção dos valores na amostra produzida seja a mesma que a proporção dos valores fornecidos para o parâmetro stratify.\n",
        "\n",
        "For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
        "Por exemplo, se a variável y for uma variável categórica binária com valores 0 e 1 e houver 25% de zeros e 75% de um, estratificar = y garantirá que sua divisão aleatória tenha 25% de 0 e 75% de 1.\n",
        "\n",
        "\n",
        "For Reference : https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f14c88ae0a061de30566d336608d195ba89993d9",
        "id": "rXDkoCiBq8rd"
      },
      "cell_type": "code",
      "source": [
        "#importing train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7081050c51df07b8af1cd18c9be61f041a97fb8",
        "id": "RVF-kK7gq8rd"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "test_scores = []\n",
        "train_scores = []\n",
        "\n",
        "for i in range(1,15):\n",
        "\n",
        "    knn = KNeighborsClassifier(i)\n",
        "    knn.fit(X_train,y_train)\n",
        "\n",
        "    train_scores.append(knn.score(X_train,y_train))\n",
        "    test_scores.append(knn.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee126a72ca24e54ee78bfac94a21dfac1a3edee1",
        "id": "zuMLzQgMq8re"
      },
      "cell_type": "code",
      "source": [
        "## score that comes from testing on the same datapoints that were used for training\n",
        "max_train_score = max(train_scores)\n",
        "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
        "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8bbfda9d066c354f974dcb1180c3348aaa915c4e",
        "id": "qBkPsCsnq8re"
      },
      "cell_type": "code",
      "source": [
        "## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
        "max_test_score = max(test_scores)\n",
        "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
        "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fe08768381ea8011d90ae58149c8e41b0a707da2",
        "id": "_pAX8-97q8re"
      },
      "cell_type": "markdown",
      "source": [
        "## Result Visualisation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a5c0b4fde15148a049fa340a58f5b4fa421e614",
        "id": "lxDR3mQTq8rf"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "p = sns.lineplot(range(1,15),train_scores,marker='*',label='Train Score')\n",
        "p = sns.lineplot(range(1,15),test_scores,marker='o',label='Test Score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1db31455aba31edc524091fa0914743a284034c5",
        "id": "A5pHbgOAq8rf"
      },
      "cell_type": "markdown",
      "source": [
        "#### The best result is captured at k = 11 hence 11 is used for the final model\n",
        "\n",
        "#### O melhor resultado é capturado em k = 1, portanto, 1 é usado para o modelo final"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "277c1bb9c48cca13536ac8ba71604818d323fae0",
        "id": "Rr6clJBpq8rg"
      },
      "cell_type": "code",
      "source": [
        "#Setup a knn classifier with k neighbors\n",
        "knn = KNeighborsClassifier(1)\n",
        "\n",
        "knn.fit(X_train,y_train)\n",
        "knn.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22878f26662e0a863c48cf43030c9e6ab57d98fc",
        "id": "cjlL8eqVq8rg"
      },
      "cell_type": "code",
      "source": [
        "## trying to plot decision boundary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e67d02ae6dbab28b27cfbd968d3717e406de53bf",
        "id": "KCTjcSgmq8rg"
      },
      "cell_type": "code",
      "source": [
        "value = 20000\n",
        "width = 20000\n",
        "plot_decision_regions(X.values, y.values, clf=knn, legend=2,\n",
        "                      filler_feature_values={2: value, 3: value, 4: value, 5: value, 6: value, 7: value,\n",
        "                                             8: value, 9: value, 10: value, 11: value, 12: value, 13: value,\n",
        "                                             14: value, 15: value, 16: value, 17: value, 18: value, 19: value,\n",
        "                                             20: value, 21: value, 22: value},\n",
        "                      filler_feature_ranges={2: width, 3: width, 4: width, 5: width, 6: width, 7: width,\n",
        "                                             8: width, 9: width, 10: width, 11: width, 12: width, 13: width,\n",
        "                                             14: width, 15: width, 16: width, 17: width, 18: width, 19: width,\n",
        "                                             20: width, 21: width, 22: width},\n",
        "                      X_highlight=X_test.values)\n",
        "\n",
        "# Adding axes annotations\n",
        "#plt.xlabel('sepal length [cm]')\n",
        "#plt.ylabel('petal length [cm]')\n",
        "plt.title('KNN com Dados de Evasão')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab1e49d83f39a6ddc780c394d3a052b49508c6ac",
        "id": "AB8ZqkNjq8rh"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Performance Analysis"
      ]
    },
    {
      "metadata": {
        "_uuid": "0b471c49636c633d40442a208c5983d607e4fa2c",
        "id": "QLqurTTaq8rh"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Matriz de Confusão\n",
        "\n",
        "The confusion matrix is a technique used for summarizing the performance of a classification algorithm i.e. it has binary outputs.\n",
        "\n",
        "A matriz de confusão é uma técnica usada para resumir o desempenho de um algoritmo de classificação, ou seja, possui saídas binárias.\n",
        "![](https://cdn-images-1.medium.com/max/1600/0*-GAP6jhtJvt7Bqiv.png)\n",
        "\n",
        "\n",
        "##### ***VERDADEIRO POSITIVO***: Os casos em que o sistema previu SIM (eles são evadidos) e eles são realmente evadidos. O sistema previu corretamente que o aluno é evadido.\n",
        "\n",
        "##### VERDADEIRO NEGATIVO: Os casos em que o sistema previu NÃO (eles não são evadidos) e eles não são evadidos. O sistema previu corretamente que o aluno não é evadido.\n",
        "\n",
        "##### FALSO POSITIVO: Os casos em que o sistema previu SIM (eles são evadidos) e eles não são evadidos.\n",
        "\n",
        "##### FALSO NEGATIVO: Os casos em que o sistema previu NÃO (eles não são evadidos) e eles são evadidos.\n",
        "\n",
        "\n",
        "\n",
        "### ***In the famous cancer example***:\n",
        "\n",
        "\n",
        "###### Cases in which the doctor predicted YES (they have the disease), and they do have the disease will be termed as TRUE POSITIVES (TP). The doctor has correctly predicted that the patient has the disease.\n",
        "\n",
        "###### Cases in which the doctor predicted NO (they do not have the disease), and they don’t have the disease will be termed as TRUE NEGATIVES (TN). The doctor has correctly predicted that the patient does not have the disease.\n",
        "\n",
        "###### Cases in which the doctor predicted YES, and they do not have the disease will be termed as FALSE POSITIVES (FP). Also known as “Type I error”.\n",
        "\n",
        "###### Cases in which the doctor predicted NO, and they have the disease will be termed as FALSE NEGATIVES (FN). Also known as “Type II error”.\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/0*9r99oJ2PTRi4gYF_.jpg)\n",
        "\n",
        "For Reference: https://medium.com/@djocz/confusion-matrix-aint-that-confusing-d29e18403327"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d09044f60af8405e7334c2062404336d0849e871",
        "id": "VAKSEK32q8ri"
      },
      "cell_type": "code",
      "source": [
        "#import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#let us get the predictions using the classifier we had fit above\n",
        "y_pred = knn.predict(X_test)\n",
        "confusion_matrix(y_test,y_pred)\n",
        "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb0b2fc2a33afeed856e2b3cc986ffb9e3e3ae7b",
        "id": "o9QC0GP6q8ri"
      },
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "from sklearn import metrics\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "plt.title('Matriz de Confusão', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "893c30414255c296b13d0d421086bb1a24cdd22c",
        "id": "qtllcckoq8rj"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Classification Report\n",
        "\n",
        "Report which includes Precision, Recall and F1-Score.\n",
        "\n",
        "\n",
        "#### Precision Score\n",
        "        TP – True Positives\n",
        "        FP – False Positives\n",
        "\n",
        "        Precision – Accuracy of positive predictions.\n",
        "        Precision = TP/(TP + FP)\n",
        "        \n",
        "   \n",
        "#### Recall Score\n",
        "        FN – False Negatives\n",
        "\n",
        "        Recall(sensitivity or true positive rate): Fraction of positives that were correctly identified.\n",
        "        Recall = TP/(TP+FN)\n",
        "        \n",
        "#### F1 Score\n",
        "        F1 Score (aka F-Score or F-Measure) – A helpful metric for comparing two classifiers.\n",
        "        F1 Score takes into account precision and the recall.\n",
        "        It is created by finding the the harmonic mean of precision and recall.\n",
        "\n",
        "        F1 = 2 x (precision x recall)/(precision + recall)\n",
        "        \n",
        "        \n",
        "        \n",
        "> > ***Precision*** - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate. We have got 0.788 precision which is pretty good.\n",
        "> >\n",
        "> > Precision = TP/TP+FP\n",
        "> >\n",
        "> > ***Recall (Sensitivity)*** - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label? A recall greater than 0.5 is good.\n",
        "> >\n",
        "> > Recall = TP/TP+FN\n",
        "> >\n",
        "> > ***F1 score*** - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall.\n",
        "> >\n",
        "> > F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
        "        \n",
        "        \n",
        "For Reference: http://joshlawman.com/metrics-classification-report-breakdown-precision-recall-f1/\n",
        "                        : https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ac998149c1f0dd304b807707f0dc44dd2b2ffb3",
        "id": "5Uml2b-9q8rj"
      },
      "cell_type": "code",
      "source": [
        "#import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7463f2aa317b5a0398aec869e94b168867ca0f0c",
        "id": "EvYZejUBq8rk"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. ROC - AUC\n",
        "ROC (Receiver Operating Characteristic) Curve tells us about how good the model can distinguish between two things (e.g If a patient has a disease or no). Better models can accurately distinguish between the two. Whereas, a poor model will have difficulties in distinguishing between the two\n",
        "\n",
        "\n",
        "Well Explained in this video: https://www.youtube.com/watch?v=OAl6eAyP-yo\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20b2083d2eaf2fca599eb6f2ef8803be0b1ac5d7",
        "id": "5d3nVLtGq8rk"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "y_pred_proba = knn.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "379eefad0181f1f57ffbb3634ab6d132af17464f",
        "id": "3eqX1GNBq8rl"
      },
      "cell_type": "code",
      "source": [
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.plot(fpr,tpr, label='Knn')\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('tpr')\n",
        "plt.title('Knn(n_neighbors=1) ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c92773e49532f6133b23d511058202bb77ff2cd",
        "id": "nTiiMATzq8rl"
      },
      "cell_type": "code",
      "source": [
        "#Area under ROC curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test,y_pred_proba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "016a40668e45c0185ba011dc0f25f20512feabb3",
        "id": "mFV2Ed4bq8rm"
      },
      "cell_type": "markdown",
      "source": [
        "# Hyper Parameter optimization\n",
        "Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.\n",
        "\n",
        "Let’s consider the following example:\n",
        "\n",
        "Suppose, a machine learning model X takes hyperparameters a1, a2 and a3. In grid searching, you first define the range of values for each of the hyperparameters a1, a2 and a3. You can think of this as an array of values for each of the hyperparameters. Now the grid search technique will construct many versions of X with all the possible combinations of hyperparameter (a1, a2 and a3) values that you defined in the first place. This range of hyperparameter values is referred to as the grid.\n",
        "\n",
        "Suppose, you defined the grid as:\n",
        "a1 = [0,1,2,3,4,5]\n",
        "a2 = [10,20,30,40,5,60]\n",
        "a3 = [105,105,110,115,120,125]\n",
        "\n",
        "Note that, the array of values of that you are defining for the hyperparameters has to be legitimate in a sense that you cannot supply Floating type values to the array if the hyperparameter only takes Integer values.\n",
        "\n",
        "Now, grid search will begin its process of constructing several versions of X with the grid that you just defined.\n",
        "\n",
        "It will start with the combination of [0,10,105], and it will end with [5,60,125]. It will go through all the intermediate combinations between these two which makes grid search computationally very expensive."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e369c794253b71d3daa1444fb7d11872fb8a110c",
        "id": "H3HaL5IEq8rm"
      },
      "cell_type": "code",
      "source": [
        "#import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#In case of classifier like knn the parameter to be tuned is n_neighbors\n",
        "param_grid = {'n_neighbors':np.arange(1,50)}\n",
        "knn = KNeighborsClassifier()\n",
        "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
        "knn_cv.fit(X,y)\n",
        "\n",
        "print(\"Best Score:\" + str(knn_cv.best_score_))\n",
        "print(\"Best Parameters: \" + str(knn_cv.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0899b30f7683581d675a185468972b2165eec04e",
        "id": "vcFI7FNmq8rn"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "875c731b163da4f47f8ec7bc27e33dfe92876e1c",
        "id": "vPEyJMVcq8rn"
      },
      "cell_type": "markdown",
      "source": [
        "#### Don't forget to share and upvote if you found my notebook of use :)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}